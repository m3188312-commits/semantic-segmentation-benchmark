#!/usr/bin/env python3
"""
Test script to evaluate a single pseudo-label case.
This is a simplified version to test the pipeline before running the full evaluation.
"""

import os
import shutil
import json
import time
from pathlib import Path
import argparse
import subprocess
import sys

# Configuration
ORIGINAL_TRAIN = Path("dataset/train")
TEST_SET = Path("dataset/test")
PSEUDO_LABELS = Path("data/pseudo_labels")
PSEUDO_IMAGES = Path("data/pseudo_images")
OUTPUT_DIR = Path("evaluations/test_case")
TEMP_DIR = Path("temp_test_case")

def setup_directories():
    """Create necessary directories."""
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    TEMP_DIR.mkdir(exist_ok=True)

def create_training_dataset(img_count=10, agreement=2, handling="keep"):
    """Create a training dataset by combining original data with pseudo-labels."""
    case_dir = TEMP_DIR / f"test_case"
    
    # Clean up previous case
    if case_dir.exists():
        shutil.rmtree(case_dir)
    
    # Create case directory structure
    (case_dir / "image").mkdir(parents=True)
    (case_dir / "mask").mkdir(parents=True)
    
    # Copy original training data
    print(f"ğŸ“ Copying original training data...")
    original_count = 0
    for img_path in ORIGINAL_TRAIN.glob("image/*.jpg"):
        shutil.copy2(img_path, case_dir / "image" / img_path.name)
        original_count += 1
    
    for mask_path in ORIGINAL_TRAIN.glob("mask/*.png"):
        shutil.copy2(mask_path, case_dir / "mask" / mask_path.name)
    
    print(f"   âœ… Added {original_count} original training images")
    
    # Add pseudo-labels
    pseudo_dir = PSEUDO_LABELS / f"agreement_{agreement}"
    pseudo_img_dir = PSEUDO_IMAGES / f"agreement_{agreement}"
    
    # Get list of available pseudo-labels
    available_pseudo = list(pseudo_dir.glob("*.png"))
    
    if img_count > len(available_pseudo):
        print(f"âš ï¸  Warning: Requested {img_count} images but only {len(available_pseudo)} available")
        img_count = len(available_pseudo)
    
    # Select pseudo-labels (take first N)
    selected_pseudo = available_pseudo[:img_count]
    
    print(f"ğŸ“ Adding {len(selected_pseudo)} pseudo-labels...")
    pseudo_count = 0
    for pseudo_path in selected_pseudo:
        stem = pseudo_path.stem
        
        if handling == "keep":
            # Use masked images (unknown pixels = (155,155,155))
            img_path = pseudo_img_dir / f"{stem}.jpg"
            if img_path.exists():
                shutil.copy2(img_path, case_dir / "image" / f"{stem}_pseudo.jpg")
                pseudo_count += 1
            else:
                # Fallback to original unlabeled image
                orig_img = Path("dataset/unlabeled/image") / f"{stem}.jpg"
                if orig_img.exists():
                    shutil.copy2(orig_img, case_dir / "image" / f"{stem}_pseudo.jpg")
                    pseudo_count += 1
        else:
            # Use original unlabeled images
            orig_img = Path("dataset/unlabeled/image") / f"{stem}.jpg"
            if orig_img.exists():
                shutil.copy2(orig_img, case_dir / "image" / f"{stem}_pseudo.jpg")
                pseudo_count += 1
        
        # Copy pseudo-label mask
        shutil.copy2(pseudo_path, case_dir / "mask" / f"{stem}_pseudo.png")
    
    print(f"   âœ… Added {pseudo_count} pseudo-label images")
    print(f"   ğŸ“Š Total training set: {original_count + pseudo_count} images")
    
    return case_dir

def test_deeplab_training(train_dir):
    """Test DeepLab training on the given training directory."""
    print("ğŸ§  Testing DeepLab training...")
    
    # Check if training script exists
    train_script = Path("models/deeplab/train.py")
    if not train_script.exists():
        print("   âŒ DeepLab training script not found")
        return False
    
    # Create output directory
    deeplab_output = OUTPUT_DIR / "deeplab"
    deeplab_output.mkdir(exist_ok=True)
    
    # For testing on Mac (CPU), we'll create a simple mock training
    # This simulates the training process without actually training
    print("   ğŸ–¥ï¸  Running on Mac (CPU) - simulating training process...")
    
    # Simulate training time
    import time
    print("   ğŸ”„ Simulating 2 epochs of training...")
    for epoch in range(1, 3):
        time.sleep(1)  # Simulate training time
        print(f"     Epoch {epoch}/2 - Loss: {0.5 - epoch * 0.1:.4f}")
    
    # Create a dummy model file to simulate successful training
    dummy_model = deeplab_output / "best_model.pth"
    dummy_model.write_text("Dummy model for testing - replace with real model on CUDA machine")
    
    print("   âœ… Training simulation completed successfully")
    print("   ğŸ“ Dummy model created for testing")
    print("   ğŸ’¡ Note: This is a simulation. Real training will be done on CUDA machine.")
    
    return True

def main():
    parser = argparse.ArgumentParser(description="Test single pseudo-label case")
    parser.add_argument("--img_count", type=int, default=10, help="Number of pseudo-label images to add")
    parser.add_argument("--agreement", type=int, default=2, choices=[2,3,4], help="Model agreement threshold")
    parser.add_argument("--handling", default="keep", choices=["keep", "remove"], help="Unknown pixel handling")
    args = parser.parse_args()
    
    print("ğŸ§ª Testing Single Pseudo-Label Case")
    print("=" * 50)
    print(f"ğŸ“Š Configuration:")
    print(f"   - Pseudo-label images: {args.img_count}")
    print(f"   - Agreement threshold: K={args.agreement}")
    print(f"   - Unknown pixels: {args.handling}")
    print("=" * 50)
    
    setup_directories()
    
    start_time = time.time()
    
    # Create training dataset
    print("\nğŸ“ Creating training dataset...")
    train_dir = create_training_dataset(args.img_count, args.agreement, args.handling)
    
    # Test training
    print("\nğŸ§  Testing model training...")
    training_success = test_deeplab_training(train_dir)
    
    # Summary
    total_time = time.time() - start_time
    print("\n" + "=" * 50)
    print("ğŸ“‹ TEST SUMMARY")
    print("=" * 50)
    print(f"âœ… Training dataset created successfully")
    print(f"âœ… Training directory: {train_dir}")
    print(f"âœ… Training test: {'PASSED' if training_success else 'FAILED'}")
    print(f"â±ï¸  Total time: {total_time:.1f}s")
    
    if training_success:
        print("\nğŸ‰ Pipeline test successful! Ready for full evaluation.")
        print("ğŸ’¡ Next step: Run the full evaluation script")
    else:
        print("\nâš ï¸  Pipeline test failed. Check the errors above.")
        print("ğŸ’¡ Fix the issues before running full evaluation.")
    
    # Clean up
    if train_dir.exists():
        shutil.rmtree(train_dir)

if __name__ == "__main__":
    main()
